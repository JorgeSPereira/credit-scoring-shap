# Credit Scoring com Interpretabilidade (SHAP)

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-green.svg)
![SHAP](https://img.shields.io/badge/SHAP-0.43+-red.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688.svg)
![MLflow](https://img.shields.io/badge/MLflow-2.10+-0194E2.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

> Modelo de Credit Scoring com foco em **interpretabilidade** utilizando SHAP, **API REST** para inferÃªncia, **MLflow** para tracking de experimentos e **anÃ¡lise de fairness** para detecÃ§Ã£o de viÃ©s.

---

## Destaques do Projeto

| Feature | DescriÃ§Ã£o |
|---------|-----------|
| **Optuna** | OtimizaÃ§Ã£o Bayesiana de hiperparÃ¢metros |
| **SHAP** | Interpretabilidade global e local |
| **FastAPI** | API REST para prediÃ§Ãµes em tempo real |
| **MLflow** | Tracking de experimentos e modelos |
| **Fairlearn** | AnÃ¡lise de viÃ©s e equidade |
| **Pandera** | ValidaÃ§Ã£o de dados |
| **CI/CD** | GitHub Actions para testes automatizados |
| **TabPFN** | Foundation Model para benchmark |


---

## Contexto de NegÃ³cio

A concessÃ£o de crÃ©dito Ã© uma das decisÃµes mais crÃ­ticas em instituiÃ§Ãµes financeiras. Um modelo de **Credit Scoring** precisa nÃ£o apenas ser preciso, mas tambÃ©m **explicÃ¡vel** para:

- **Compliance regulatÃ³rio** (LGPD, BACEN)
- **TransparÃªncia** com clientes (direito Ã  explicaÃ§Ã£o)
- **ValidaÃ§Ã£o de negÃ³cio** (features fazem sentido?)
- **DetecÃ§Ã£o de viÃ©s** em variÃ¡veis sensÃ­veis

---

## Arquitetura do Pipeline

```mermaid
flowchart LR
    subgraph Data["ðŸ“Š Data"]
        A[German Credit Dataset] --> B[Pandera Validation]
    end
    
    subgraph Training["ðŸ”§ Training"]
        B --> C[Feature Engineering]
        C --> D[Optuna HPO]
        D --> E[XGBoost/LightGBM]
    end
    
    subgraph Tracking["ðŸ“ˆ MLOps"]
        E --> F[MLflow Tracking]
        F --> G[Model Registry]
    end
    
    subgraph Deploy["ðŸš€ Deploy"]
        G --> H[FastAPI]
        H --> I["/predict endpoint"]
    end
    
    subgraph Analysis["ðŸ” Analysis"]
        E --> J[SHAP Interpretability]
        E --> K[Fairness Analysis]
        E --> L[Cost/Profit Analysis]
    end
```

---

## Fluxo de DecisÃ£o de CrÃ©dito

```mermaid
flowchart TD
    A["ðŸ§‘ Cliente solicita crÃ©dito"] --> B["ðŸ“ Coleta de Dados"]
    B --> C["âš™ï¸ Preprocessamento"]
    C --> D["ðŸ¤– Modelo XGBoost"]
    
    subgraph Threshold["ðŸ’° OtimizaÃ§Ã£o de Lucro"]
        T1["cost_analysis.py"] --> T2["Threshold Ã“timo: 0.45"]
    end
    
    T2 -.-> E
    D --> E{"P(default) > threshold?"}
    
    E -->|Sim| F["âŒ CrÃ©dito Negado"]
    E -->|NÃ£o| G["âœ… CrÃ©dito Aprovado"]
    
    D --> H["ðŸ” SHAP Explanation"]
    H --> I["ðŸ“‹ Justificativa para Cliente"]
    
    F --> J["ðŸ“Š Fairness Monitoring"]
    G --> J
    
    style I fill:#e1f5fe,stroke:#01579b
```

###  Zoom: Justificativa para Cliente

O mÃ³dulo `explanation.py` transforma SHAP values em explicaÃ§Ãµes legÃ­veis:

```json
// CrÃ©dito NEGADO
{
  "decision": "NEGADO",
  "probability_default": 78.1,
  "risk_level": "ALTO",
  "main_factors": [
    {"feature": "Status da conta corrente", "impact": "aumenta risco"},
    {"feature": "Tipo de moradia", "impact": "aumenta risco"}
  ],
  "summary": "CrÃ©dito NEGADO. NÃ­vel de risco: ALTO. Principal fator: Status da conta corrente."
}

// CrÃ©dito APROVADO
{
  "decision": "APROVADO",
  "probability_default": 22.2,
  "risk_level": "BAIXO",
  "summary": "CrÃ©dito APROVADO! Seu perfil foi avaliado positivamente."
}
```

---

## AnÃ¡lise de Fairness

```mermaid
flowchart LR
    subgraph Input["Dados"]
        A[PrediÃ§Ãµes do Modelo]
        B[Atributos SensÃ­veis]
    end
    
    subgraph Metrics["MÃ©tricas Fairlearn"]
        C[Demographic Parity]
        D[Equalized Odds]
        E[Selection Rate]
    end
    
    subgraph Output["Resultado"]
        F{ViÃ©s detectado?}
        G["âœ… Fair"]
        H["âš ï¸ MitigaÃ§Ã£o necessÃ¡ria"]
    end
    
    A --> C
    B --> C
    A --> D
    B --> D
    A --> E
    B --> E
    
    C --> F
    D --> F
    E --> F
    
    F -->|NÃ£o| G
    F -->|Sim| H
```



## Resultados

### MÃ©tricas de Performance

| Modelo | ROC-AUC | PR-AUC | F1-Score |
|--------|---------|--------|----------|
| TabPFN (Foundation) | **0.814** | **0.668** | 0.577 |
| XGBoost (Optuna) | 0.806 | 0.633 | 0.658 |
| LightGBM (Optuna) | 0.782 | 0.61 | 0.581 |

### Benchmark: Literatura

| MÃ©trica | Nosso Modelo | Literatura* | AvaliaÃ§Ã£o |
|---------|--------------|-------------|----------|
| **ROC-AUC** | 0.81 | 0.75-0.82 | Excelente |
| **PR-AUC** | 0.67 | 0.55-0.70 | Muito bom |
| **F1-Score** | 0.66 | 0.55-0.65 | Acima da mÃ©dia |

*Valores baseados em estudos com German Credit Dataset (UCI).

> **InterpretaÃ§Ã£o**: PR-AUC de 0.67 Ã© 2.2x melhor que o baseline aleatÃ³rio (0.30), indicando boa capacidade preditiva para a classe minoritÃ¡ria.

### Por que mÃºltiplas mÃ©tricas?

| MÃ©trica | O que mede | Quando usar |
|---------|-----------|-------------|
| **ROC-AUC** | Capacidade discriminativa geral | Dataset moderadamente desbalanceado |
| **PR-AUC** | Precision-Recall trade-off | Quando classe positiva Ã© rara |
| **F1-Score** | EquilÃ­brio precision/recall | DecisÃµes com threshold fixo |

### AnÃ¡lise de Custo (Cost-Sensitive)

Em credit scoring, os custos sÃ£o **assimÃ©tricos**:

| Erro | Custo tÃ­pico | Impacto |
|------|--------------|---------|
| **FN** (emprestar para mau) | -R$1000 | Perde o principal |
| **FP** (negar para bom) | -R$200 | Perde margem |

O mÃ³dulo `cost_analysis.py` encontra o **threshold Ã³timo** que maximiza lucro.

---

## Foundation Models Comparison

Este projeto explora **Foundation Models** para dados tabulares, comparando performance vs interpretabilidade.

### Resultados

| Modelo | ROC-AUC | PR-AUC | Interpretabilidade |
|--------|---------|--------|-------------------|
| **TabPFN** | **0.814** | **0.668** | Limitada |
| XGBoost + SHAP | 0.806 | 0.633 | Excelente |

### Trade-off: Performance vs Explicabilidade

> **Importante**: Em credit scoring, a **explicabilidade Ã© requisito regulatÃ³rio** (LGPD, BACEN).

| CenÃ¡rio | Modelo Recomendado |
|---------|-------------------|
| ProduÃ§Ã£o (regulado) | XGBoost + SHAP |
| Prototipo/PoC | TabPFN |

Para detalhes, veja: `notebooks/05_foundation_models.ipynb`





## InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/credit-scoring-shap.git
cd credit-scoring-shap

# Instale as dependÃªncias
poetry install

# Ative o ambiente
poetry shell
```

---

## Uso

### Treinar Modelo

```bash
# Com otimizaÃ§Ã£o Optuna (recomendado)
make train

# Treinamento rÃ¡pido (sem Optuna)
make train-quick
```

### API REST

```bash
# Iniciar servidor
make api

# Testar endpoint
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"duration": 24, "credit_amount": 5000, ...}'
```

ApÃ³s iniciar, acesse a documentaÃ§Ã£o interativa (Swagger UI) em: `http://localhost:8000/docs`

### MLflow Tracking

```bash
# Iniciar UI do MLflow
make mlflow

# Acessar em: http://localhost:5000
```

### AnÃ¡lise de Fairness

```bash
# Executar notebook de fairness
make fairness
```

### Notebooks

```bash
poetry run jupyter notebook

# Ordem recomendada:
# 1. 01_eda.ipynb - AnÃ¡lise exploratÃ³ria
# 2. 02_modeling.ipynb - Modelagem com Optuna
# 3. 03_interpretability.ipynb - AnÃ¡lise SHAP
# 4. 04_fairness.ipynb - DetecÃ§Ã£o de viÃ©s
# 5. 05_foundation_models.ipynb - TabPFN comparison
```

---

## Estrutura do Projeto

```
credit-scoring-shap/
â”œâ”€â”€ .github/workflows/      # CI/CD
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ src/credit_scoring/
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
â”‚   â”œâ”€â”€ data/               # Loaders + validaÃ§Ã£o
â”‚   â”œâ”€â”€ fairness/           # AnÃ¡lise de viÃ©s
â”‚   â”œâ”€â”€ features/           # Feature engineering
â”‚   â”œâ”€â”€ interpretability/   # SHAP analysis
â”‚   â”œâ”€â”€ models/             # Training + evaluation
â”‚   â””â”€â”€ tracking/           # MLflow integration
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_modeling.ipynb
â”‚   â”œâ”€â”€ 03_interpretability.ipynb
â”‚   â””â”€â”€ 04_fairness.ipynb
â”œâ”€â”€ tests/
â”œâ”€â”€ models/                 # Modelos salvos
â”œâ”€â”€ reports/                # MÃ©tricas e figuras
â”œâ”€â”€ pyproject.toml
â””â”€â”€ Makefile
```

---

## Tecnologias

| Categoria | Ferramentas |
|-----------|-------------|
| **ML** | scikit-learn, XGBoost, LightGBM |
| **OtimizaÃ§Ã£o** | Optuna |
| **Interpretabilidade** | SHAP |
| **Fairness** | Fairlearn |
| **API** | FastAPI, Uvicorn |
| **Tracking** | MLflow |
| **ValidaÃ§Ã£o** | Pandera |
| **VisualizaÃ§Ã£o** | Matplotlib, Seaborn, Plotly |
| **Qualidade** | Black, Flake8, isort, mypy, pre-commit |
| **CI/CD** | GitHub Actions |
| **Ambiente** | Poetry |

---

## Comandos Makefile

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| `make install` | Instalar dependÃªncias |
| `make train` | Treinar com Optuna |
| `make train-quick` | Treinar sem Optuna |
| `make api` | Iniciar API |
| `make mlflow` | Iniciar MLflow UI |
| `make fairness` | Executar anÃ¡lise de fairness |
| `make test` | Rodar testes |
| `make format` | Formatar cÃ³digo |
| `make lint` | Verificar linting |

---

## ReferÃªncias

- [German Credit Dataset - UCI](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MLflow Documentation](https://mlflow.org/docs/latest/)
- [Fairlearn Documentation](https://fairlearn.org/)

---

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

## Autor

**Jorge Silva Pereira** - Analista de Dados

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://www.linkedin.com/in/jorgepereira-/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black)](https://github.com/JorgeSPereira)
