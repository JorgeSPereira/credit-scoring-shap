# Credit Scoring com Interpretabilidade (SHAP)

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3+-orange.svg)
![XGBoost](https://img.shields.io/badge/XGBoost-2.0+-green.svg)
![SHAP](https://img.shields.io/badge/SHAP-0.43+-red.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-009688.svg)
![MLflow](https://img.shields.io/badge/MLflow-2.10+-0194E2.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

> Modelo de Credit Scoring com foco em **interpretabilidade** utilizando SHAP, **API REST** para inferÃªncia, **MLflow** para tracking de experimentos e **anÃ¡lise de fairness** para detecÃ§Ã£o de viÃ©s.

---

## Destaques do Projeto

| Feature | DescriÃ§Ã£o |
|---------|-----------|
| **Optuna** | OtimizaÃ§Ã£o Bayesiana de hiperparÃ¢metros |
| **SHAP** | Interpretabilidade global e local |
| **FastAPI** | API REST para prediÃ§Ãµes em tempo real |
| **MLflow** | Tracking de experimentos e modelos |
| **Fairlearn** | AnÃ¡lise de viÃ©s e equidade |
| **Pandera** | ValidaÃ§Ã£o de dados |
| **CI/CD** | GitHub Actions para testes automatizados |

---

## Contexto de NegÃ³cio

A concessÃ£o de crÃ©dito Ã© uma das decisÃµes mais crÃ­ticas em instituiÃ§Ãµes financeiras. Um modelo de **Credit Scoring** precisa nÃ£o apenas ser preciso, mas tambÃ©m **explicÃ¡vel** para:

- **Compliance regulatÃ³rio** (LGPD, BACEN)
- **TransparÃªncia** com clientes (direito Ã  explicaÃ§Ã£o)
- **ValidaÃ§Ã£o de negÃ³cio** (features fazem sentido?)
- **DetecÃ§Ã£o de viÃ©s** em variÃ¡veis sensÃ­veis

---

## Arquitetura do Pipeline

```mermaid
flowchart LR
    subgraph Data["ðŸ“Š Data"]
        A[German Credit Dataset] --> B[Pandera Validation]
    end
    
    subgraph Training["ðŸ”§ Training"]
        B --> C[Feature Engineering]
        C --> D[Optuna HPO]
        D --> E[XGBoost/LightGBM]
    end
    
    subgraph Tracking["ðŸ“ˆ MLOps"]
        E --> F[MLflow Tracking]
        F --> G[Model Registry]
    end
    
    subgraph Deploy["ðŸš€ Deploy"]
        G --> H[FastAPI]
        H --> I["/predict endpoint"]
    end
    
    subgraph Analysis["ðŸ” Analysis"]
        E --> J[SHAP Interpretability]
        E --> K[Fairness Analysis]
    end
```

---

## Fluxo de DecisÃ£o de CrÃ©dito

```mermaid
flowchart TD
    A["ðŸ§‘ Cliente solicita crÃ©dito"] --> B["ðŸ“ Dados coletados"]
    B --> C["âš™ï¸ Preprocessamento"]
    C --> D["ðŸ¤– Modelo XGBoost"]
    D --> E{"P(default) > threshold?"}
    
    E -->|Sim| F["âŒ CrÃ©dito Negado"]
    E -->|NÃ£o| G["âœ… CrÃ©dito Aprovado"]
    
    D --> H["ðŸ” SHAP Explanation"]
    H --> I["ðŸ“‹ Justificativa para cliente"]
    
    F --> J["ðŸ“Š Fairness Monitoring"]
    G --> J
```

---

## AnÃ¡lise de Fairness

```mermaid
flowchart LR
    subgraph Input["Dados"]
        A[PrediÃ§Ãµes do Modelo]
        B[Atributos SensÃ­veis]
    end
    
    subgraph Metrics["MÃ©tricas Fairlearn"]
        C[Demographic Parity]
        D[Equalized Odds]
        E[Selection Rate]
    end
    
    subgraph Output["Resultado"]
        F{ViÃ©s detectado?}
        G["âœ… Fair"]
        H["âš ï¸ MitigaÃ§Ã£o necessÃ¡ria"]
    end
    
    A --> C
    B --> C
    A --> D
    B --> D
    A --> E
    B --> E
    
    C --> F
    D --> F
    E --> F
    
    F -->|NÃ£o| G
    F -->|Sim| H
```



## Resultados

| Modelo | ROC-AUC | Precision | Recall | F1-Score |
|--------|---------|-----------|--------|----------|
| Logistic Regression | **0.806** | 0.537 | 0.720 | 0.658 |
| XGBoost (Optuna) | 0.781 | **0.560** | 0.589 | 0.573 |
| LightGBM (Optuna) | 0.782 | 0.545 | 0.600 | 0.581 |

---

## Foundation Models Comparison

Este projeto tambÃ©m explora **Foundation Models** para dados tabulares, comparando performance vs interpretabilidade.

### Modelos Avaliados

| Modelo | Tipo | Performance | Interpretabilidade |
|--------|------|-------------|-------------------|
| **XGBoost + SHAP** | Gradient Boosting | Boa | Excelente |
| **TabPFN** | Transformer pre-treinado | Excelente | Limitada |
| **MITRA** (AutoGluon) | Foundation Model | State-of-the-art | Limitada |

### Trade-off: Performance vs Explicabilidade

> **Importante**: Em credit scoring, a **explicabilidade Ã© requisito regulatÃ³rio** (LGPD, BACEN).

| CenÃ¡rio | Modelo Recomendado |
|---------|-------------------|
| ProduÃ§Ã£o (regulado) | XGBoost + SHAP |
| Prototipo/PoC | TabPFN/MITRA |
| Benchmark interno | Comparar todos |

Para detalhes, veja: `notebooks/05_foundation_models.ipynb`



## InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/credit-scoring-shap.git
cd credit-scoring-shap

# Instale as dependÃªncias
poetry install

# Ative o ambiente
poetry shell
```

---

## Uso

### Treinar Modelo

```bash
# Com otimizaÃ§Ã£o Optuna (recomendado)
make train

# Treinamento rÃ¡pido (sem Optuna)
make train-quick
```

### API REST

```bash
# Iniciar servidor
make api

# Testar endpoint
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"duration": 24, "credit_amount": 5000, ...}'
```

Acesse a documentaÃ§Ã£o interativa em: `http://localhost:8000/docs`

### MLflow Tracking

```bash
# Iniciar UI do MLflow
make mlflow

# Acessar em: http://localhost:5000
```

### AnÃ¡lise de Fairness

```bash
# Executar notebook de fairness
make fairness
```

### Notebooks

```bash
poetry run jupyter notebook

# Ordem recomendada:
# 1. 01_eda.ipynb - AnÃ¡lise exploratÃ³ria
# 2. 02_modeling.ipynb - Modelagem com Optuna
# 3. 03_interpretability.ipynb - AnÃ¡lise SHAP
# 4. 04_fairness.ipynb - DetecÃ§Ã£o de viÃ©s
# 5. 05_foundation_models.ipynb - TabPFN/MITRA
```

---

## Estrutura do Projeto

```
credit-scoring-shap/
â”œâ”€â”€ .github/workflows/      # CI/CD
â”‚   â””â”€â”€ ci.yml
â”œâ”€â”€ src/credit_scoring/
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
â”‚   â”œâ”€â”€ data/               # Loaders + validaÃ§Ã£o
â”‚   â”œâ”€â”€ fairness/           # AnÃ¡lise de viÃ©s
â”‚   â”œâ”€â”€ features/           # Feature engineering
â”‚   â”œâ”€â”€ interpretability/   # SHAP analysis
â”‚   â”œâ”€â”€ models/             # Training + evaluation
â”‚   â””â”€â”€ tracking/           # MLflow integration
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_modeling.ipynb
â”‚   â”œâ”€â”€ 03_interpretability.ipynb
â”‚   â””â”€â”€ 04_fairness.ipynb
â”œâ”€â”€ tests/
â”œâ”€â”€ models/                 # Modelos salvos
â”œâ”€â”€ reports/                # MÃ©tricas e figuras
â”œâ”€â”€ pyproject.toml
â””â”€â”€ Makefile
```

---

## Tecnologias

| Categoria | Ferramentas |
|-----------|-------------|
| **ML** | scikit-learn, XGBoost, LightGBM |
| **OtimizaÃ§Ã£o** | Optuna |
| **Interpretabilidade** | SHAP |
| **Fairness** | Fairlearn |
| **API** | FastAPI, Uvicorn |
| **Tracking** | MLflow |
| **ValidaÃ§Ã£o** | Pandera |
| **VisualizaÃ§Ã£o** | Matplotlib, Seaborn, Plotly |
| **Qualidade** | Black, Flake8, isort, mypy, pre-commit |
| **CI/CD** | GitHub Actions |
| **Ambiente** | Poetry |

---

## Comandos Makefile

| Comando | DescriÃ§Ã£o |
|---------|-----------|
| `make install` | Instalar dependÃªncias |
| `make train` | Treinar com Optuna |
| `make train-quick` | Treinar sem Optuna |
| `make api` | Iniciar API |
| `make mlflow` | Iniciar MLflow UI |
| `make fairness` | Executar anÃ¡lise de fairness |
| `make test` | Rodar testes |
| `make format` | Formatar cÃ³digo |
| `make lint` | Verificar linting |

---

## ReferÃªncias

- [German Credit Dataset - UCI](https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data)
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Optuna Documentation](https://optuna.readthedocs.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [MLflow Documentation](https://mlflow.org/docs/latest/)
- [Fairlearn Documentation](https://fairlearn.org/)

---

## LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

---

## Autor

**Jorge** - Cientista de Dados

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue)](https://linkedin.com/in/seu-perfil)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black)](https://github.com/seu-usuario)

