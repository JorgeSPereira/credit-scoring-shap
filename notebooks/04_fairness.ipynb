{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analise de Fairness (Equidade)\n",
                "## Deteccao de Vies em Modelos de Credit Scoring\n",
                "\n",
                "Este notebook analisa se o modelo de credit scoring apresenta vieses em relacao a:\n",
                "- **Idade**: Discriminacao contra jovens ou idosos\n",
                "- **Genero**: Disparidade entre homens e mulheres\n",
                "\n",
                "### Por que Fairness importa?\n",
                "\n",
                "| Aspecto | Impacto |\n",
                "|---------|--------|\n",
                "| **Regulatorio** | LGPD, BACEN exigem transparencia |\n",
                "| **Reputacional** | Discriminacao gera dano de imagem |\n",
                "| **Etico** | Decisoes justas sao um imperativo moral |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 1. Configuracao"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from credit_scoring.data.loader import load_german_credit\n",
                "from credit_scoring.models.train import load_model\n",
                "from credit_scoring.fairness.analysis import (\n",
                "    create_sensitive_features,\n",
                "    analyze_fairness,\n",
                "    plot_fairness_comparison,\n",
                "    print_fairness_report,\n",
                ")\n",
                "\n",
                "print(\"Bibliotecas carregadas!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Carregar dados e modelo\n",
                "X, y = load_german_credit(save_raw=False)\n",
                "\n",
                "# Carregar modelo treinado\n",
                "model = load_model('../models/best_model_optuna.joblib')\n",
                "\n",
                "print(f\"Dataset: {X.shape[0]} amostras\")\n",
                "print(f\"Modelo carregado: {type(model).__name__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 2. Atributos Sensiveis\n",
                "\n",
                "Identificamos os atributos que podem levar a discriminacao:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Criar grupos sensiveis\n",
                "sensitive = create_sensitive_features(X)\n",
                "\n",
                "print(\"Distribuicao por Idade:\")\n",
                "print(sensitive['age_group'].value_counts())\n",
                "print(\"\\nDistribuicao por Genero:\")\n",
                "print(sensitive['gender'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualizar distribuicao\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
                "\n",
                "sensitive['age_group'].value_counts().plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='black')\n",
                "axes[0].set_title('Distribuicao por Faixa Etaria', fontweight='bold')\n",
                "axes[0].set_xlabel('Faixa Etaria')\n",
                "axes[0].set_ylabel('Contagem')\n",
                "axes[0].tick_params(axis='x', rotation=45)\n",
                "\n",
                "sensitive['gender'].value_counts().plot(kind='bar', ax=axes[1], color=['#e74c3c', '#3498db'], edgecolor='black')\n",
                "axes[1].set_title('Distribuicao por Genero', fontweight='bold')\n",
                "axes[1].set_xlabel('Genero')\n",
                "axes[1].set_ylabel('Contagem')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/fairness_distribution.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 3. Analise de Fairness"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Executar analise completa\n",
                "fairness_results = analyze_fairness(\n",
                "    model=model,\n",
                "    X=X,\n",
                "    y_true=y,\n",
                "    sensitive_columns=['age_group', 'gender']\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Relatorio detalhado\n",
                "print_fairness_report(fairness_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. Visualizacoes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grafico de Selection Rate\n",
                "fig = plot_fairness_comparison(\n",
                "    fairness_results,\n",
                "    metric='selection_rate',\n",
                "    save_path='../reports/figures/fairness_selection_rate.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Grafico de False Positive Rate\n",
                "fig = plot_fairness_comparison(\n",
                "    fairness_results,\n",
                "    metric='false_positive_rate',\n",
                "    save_path='../reports/figures/fairness_fpr.png'\n",
                ")\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 5. Metricas de Fairness\n",
                "\n",
                "### Definicoes:\n",
                "\n",
                "| Metrica | Definicao | Meta |\n",
                "|---------|-----------|------|\n",
                "| **Demographic Parity** | P(Y=1 \\| A=a) = P(Y=1 \\| A=b) | Difference < 0.1 |\n",
                "| **Equalized Odds** | TPR e FPR iguais entre grupos | Difference < 0.1 |\n",
                "| **Selection Rate** | Taxa de aprovacao por grupo | Similar entre grupos |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resumo das metricas\n",
                "summary = []\n",
                "for attr, results in fairness_results.items():\n",
                "    summary.append({\n",
                "        'Atributo': attr,\n",
                "        'Demographic Parity Diff': results['demographic_parity_difference'],\n",
                "        'Demographic Parity Ratio': results['demographic_parity_ratio'],\n",
                "        'Equalized Odds Diff': results['equalized_odds_difference'],\n",
                "        'Equalized Odds Ratio': results['equalized_odds_ratio'],\n",
                "    })\n",
                "\n",
                "summary_df = pd.DataFrame(summary)\n",
                "print(\"\\nRESUMO DAS METRICAS DE FAIRNESS\")\n",
                "print(\"=\" * 70)\n",
                "print(summary_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## 6. Interpretacao e Recomendacoes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"CONCLUSOES DA ANALISE DE FAIRNESS\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "for attr, results in fairness_results.items():\n",
                "    dpd = abs(results['demographic_parity_difference'])\n",
                "    \n",
                "    print(f\"\\n{attr.upper()}:\")\n",
                "    if dpd < 0.1:\n",
                "        print(\"  Status: FAIR\")\n",
                "        print(\"  O modelo nao apresenta vies significativo.\")\n",
                "    elif dpd < 0.2:\n",
                "        print(\"  Status: ATENCAO\")\n",
                "        print(\"  Vies moderado detectado. Considerar mitigacao.\")\n",
                "    else:\n",
                "        print(\"  Status: CRITICO\")\n",
                "        print(\"  Vies significativo! Necessaria intervencao.\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 70)\n",
                "print(\"RECOMENDACOES:\")\n",
                "print(\"  1. Monitorar metricas de fairness em producao\")\n",
                "print(\"  2. Considerar tecnicas de mitigacao (reweighting, threshold adjustment)\")\n",
                "print(\"  3. Documentar analise para compliance regulatorio\")\n",
                "print(\"=\" * 70)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Salvar resultados\n",
                "summary_df.to_csv('../reports/fairness_metrics.csv', index=False)\n",
                "print(\"Metricas salvas em: reports/fairness_metrics.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}