{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Foundation Models para Dados Tabulares\n",
                "## Comparacao: XGBoost vs TabPFN\n",
                "\n",
                "### Trade-off: Performance vs Interpretabilidade\n",
                "\n",
                "| Modelo | Performance | Interpretabilidade |\n",
                "|--------|-------------|-------------------|\n",
                "| XGBoost + SHAP | Boa | **Excelente** |\n",
                "| TabPFN | **Excelente** | Limitada |\n",
                "\n",
                "> **Em credit scoring, explicabilidade e requisito regulatorio (LGPD, BACEN).**\n",
                "\n",
                "### Requisito: HuggingFace Token\n",
                "TabPFN v6+ requer autenticacao. Configure `HF_TOKEN` como variavel de ambiente."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Setup completo!\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '../src')\n",
                "\n",
                "import os\n",
                "# Configure seu token: os.environ['HF_TOKEN'] = 'seu_token'\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score\n",
                "\n",
                "from credit_scoring.data.loader import load_german_credit\n",
                "from credit_scoring.models.train import load_model\n",
                "\n",
                "print(\"Setup completo!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Treino: 800 | Teste: 200\n"
                    ]
                }
            ],
            "source": [
                "X, y = load_german_credit(save_raw=False)\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "print(f\"Treino: {len(X_train)} | Teste: {len(X_test)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## XGBoost (Baseline)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "XGBoost ROC-AUC: 0.8058\n"
                    ]
                }
            ],
            "source": [
                "xgb_model = load_model('../models/best_model_optuna.joblib')\n",
                "xgb_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
                "xgb_pred = xgb_model.predict(X_test)\n",
                "\n",
                "xgb_metrics = {\n",
                "    'Model': 'XGBoost (Optuna)',\n",
                "    'ROC-AUC': roc_auc_score(y_test, xgb_proba),\n",
                "    'F1-Score': f1_score(y_test, xgb_pred),\n",
                "    'Precision': precision_score(y_test, xgb_pred),\n",
                "    'Recall': recall_score(y_test, xgb_pred),\n",
                "    'Interpretable': 'Sim (SHAP)'\n",
                "}\n",
                "print(f\"XGBoost ROC-AUC: {xgb_metrics['ROC-AUC']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## TabPFN (Foundation Model)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Inicializando TabPFN...\nTreinando...\nFazendo predicoes...\nTabPFN ROC-AUC: 0.8142\n"
                    ]
                }
            ],
            "source": [
                "from tabpfn import TabPFNClassifier\n",
                "\n",
                "X_train_p = xgb_model.named_steps['preprocessor'].transform(X_train)\n",
                "X_test_p = xgb_model.named_steps['preprocessor'].transform(X_test)\n",
                "\n",
                "print(\"Inicializando TabPFN...\")\n",
                "tabpfn = TabPFNClassifier()\n",
                "\n",
                "print(\"Treinando...\")\n",
                "tabpfn.fit(X_train_p, y_train)\n",
                "\n",
                "print(\"Fazendo predicoes...\")\n",
                "tabpfn_proba = tabpfn.predict_proba(X_test_p)[:, 1]\n",
                "tabpfn_pred = tabpfn.predict(X_test_p)\n",
                "\n",
                "tabpfn_metrics = {\n",
                "    'Model': 'TabPFN',\n",
                "    'ROC-AUC': roc_auc_score(y_test, tabpfn_proba),\n",
                "    'F1-Score': f1_score(y_test, tabpfn_pred),\n",
                "    'Precision': precision_score(y_test, tabpfn_pred),\n",
                "    'Recall': recall_score(y_test, tabpfn_pred),\n",
                "    'Interpretable': 'Limitada'\n",
                "}\n",
                "print(f\"TabPFN ROC-AUC: {tabpfn_metrics['ROC-AUC']:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Comparacao Final"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n============================================================\nCOMPARACAO: XGBoost vs TabPFN\n============================================================\n            Model   ROC-AUC  F1-Score  Precision  Recall Interpretable\n           TabPFN  0.814167  0.576923   0.681818     0.5      Limitada\nXGBoost (Optuna)  0.805833  0.657534   0.558140     0.8    Sim (SHAP)\n"
                    ]
                }
            ],
            "source": [
                "results = [xgb_metrics, tabpfn_metrics]\n",
                "comparison_df = pd.DataFrame(results).sort_values('ROC-AUC', ascending=False)\n",
                "\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"COMPARACAO: XGBoost vs TabPFN\")\n",
                "print(\"=\" * 60)\n",
                "print(comparison_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Salvo em: reports/foundation_models_comparison.csv\n"
                    ]
                }
            ],
            "source": [
                "fig, ax = plt.subplots(figsize=(10, 4))\n",
                "\n",
                "models = comparison_df['Model'].tolist()\n",
                "auc_scores = comparison_df['ROC-AUC'].tolist()\n",
                "colors = ['#9b59b6' if 'TabPFN' in m else '#2ecc71' for m in models]\n",
                "\n",
                "bars = ax.barh(models, auc_scores, color=colors, edgecolor='black')\n",
                "for bar, score in zip(bars, auc_scores):\n",
                "    ax.text(score + 0.005, bar.get_y() + bar.get_height()/2, \n",
                "            f'{score:.4f}', va='center', fontweight='bold')\n",
                "\n",
                "ax.set_xlabel('ROC-AUC Score', fontsize=12)\n",
                "ax.set_title('XGBoost vs TabPFN (Foundation Model)', fontsize=14, fontweight='bold')\n",
                "ax.set_xlim(0.70, 0.90)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('../reports/figures/foundation_models_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "comparison_df.to_csv('../reports/foundation_models_comparison.csv', index=False)\n",
                "print(\"Salvo em: reports/foundation_models_comparison.csv\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusao\n",
                "\n",
                "| Modelo | ROC-AUC | Recomendacao |\n",
                "|--------|---------|-------------|\n",
                "| **TabPFN** | **0.8142** | Prototipo/Benchmark |\n",
                "| XGBoost | 0.8058 | **Producao (SHAP)** |\n",
                "\n",
                "TabPFN superou XGBoost em ROC-AUC, mas XGBoost oferece interpretabilidade essencial para compliance."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}